# 日本語単語読み推定データセット

## 概要
本データセットは、日本語単語の読み推定タスクの評価用データセットです。  
読みの曖昧性のある日本語単語について、用例を収集または生成し、人手で正解の読みを付与しました。  
主に日本語の読み推定システムの評価に用いることを想定しています。

## データセットの説明
* 対象単語(読みの曖昧性がある単語)の数は50です。
* それぞれの対象単語に対し用例を100〜134件収録しています。
* 各用例には正解の読みの情報が付与されています。
* 用例は、日本語 Wikipedia の 2023-05-01 版のダンプデータから対象単語を含む文を検索し、ランダムにサンプリングしています。
* 一部の用例は ChatGPT 3.5 で生成しています。
* 以下の2つのデータセットを公開します。  
(1)標本抽出データセット  
(2)標本均等化データセット

## 標本抽出データセットについて
* 本データセットでは、対象単語1つにつき100個の用例が収録されています。
* 本データセットにおける読みの分布は実際の使用分布に近くなっています。
複数の読みがあっても1つの読みだけがよく使われるなど、一般に漢字読みの分布には偏りがありますが、その偏りがおおむね反映されています。
* ただし、どの読みも最低10件の用例を収録するようにしています。
* 収録されている用例のほとんどは Wikipedia から抽出されたものです。

## 標本均等化データセットについて
* 本データセットにおける読みの分布は均等に近くなっています。
* 具体的には、全ての読みについて30個以上の用例を収録しています。
* 標本抽出データセットにおいて用例の数が30未満である読みについて、その読みの用例を ChatGPT を用いて生成し、標本均等化データセットに追加しました。
* したがって、標本抽出データセットは標本均等化データセットに包含されます。  
(標本抽出データセット ⊂ 標本均等化データセット)

## ファイル一覧
* ja_yomi_dataset_sampling.xlsx  
標本抽出データセット (Excelファイル)
* ja_yomi_dataset_sampling.xlsx  
標本抽出データセット (タブ区切りテキストファイル)  
内容は Excel 版と同じです。
* summary_sampling.txt  
標本抽出データセットの概要  
対象単語のID、対象単語、用例数、読み(その読みの用例数)を記載しています。
* stats_sampling.txt  
標本抽出データセットの統計情報
* ja_yomi_dataset_balanced.xlsx  
標本均等化データセット (Excelファイル)
* ja_yomi_dataset_balanced.txt  
標本均等化データセット (タブ区切りテキストファイル)  
内容は Excel 版と同じです。
* summary_sampling.txt  
標本均等化データセットの概要  
対象単語のID、対象単語、用例数、読み(その読みの用例数)を記載しています。
* stats_sampling.txt  
標本均等化データセットの統計情報
* presentation_slide.pdf  
本データセットに関する発表資料  
　国立国語研究所 異分野融合型共同研究 2024年度 ワークショップ  
　2025年2月27日  
　国立国語研究所  
　白井清昭(北陸先端科学技術大学院大学)  

## ファイルの仕様
データセットにおけるフィールドの定義は以下の通りです。  

```
word_id		対象単語のID
word		対象単語(漢字表記)
inst_id		用例のID
yomi		正解の読み
type		データセットの種類 [注1]
		sampling = 標本抽出データセットの用例
		balanced = 標本均等化データセット構築の際に追加された用例
source		用例のソース
		Wikipedia = 日本語 Wikipedia から抽出した用例
		ChatGPT = ChatGPT で生成した用例
data		データセットの分割 [注2]
		train = 訓練データ
		val = 開発データ
		test = テストデータ
sentence	用例
		対象単語は * でマークアップされています

```

- [注1]  
標本抽出データセットではこのフィールドは常に sampling です。
- [注2]  
本データセットは小規模なため読み推定タスクの評価用データとして用いることを想定していますが、データセットでモデルの訓練と評価の両方を行う場合のデータセットの分割案を示しています。サンプルをランダムに8:1:1に分割し、それぞれ訓練データ、開発データ、テストデータとしています。


統計情報のファイル(stats_sampling.txt, stats_balanced.txt)におけるフィールドの定義は以下の通りです。
```
word_id		対象単語のID
yomi		読み
all		全用例数
all(wiki)	all のうち、Wikipedia から抽出した用例数
all(gpt)	all のうち、ChatGPT によって生成した用例数
train		訓練データにおける用例数
train(wiki)	train のうち、Wikipedia から抽出した用例数
train(gpt)	train のうち、ChatGPT によって生成した用例数
val		開発データにおける用例数
val(wiki)	val のうち、Wikipedia から抽出した用例数
val(gpt)	val のうち、ChatGPT によって生成した用例数
test		テストデータにおける用例数
test(wiki)	test のうち、Wikipedia から抽出した用例数
test(gpt)	test のうち、ChatGPT によって生成した用例数
```

## ライセンス
本データセットは Creative Commons Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0) および GNU Free Documentation License (GFDL) の下にライセンスされています。
- [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)
- [GFDL](https://www.gnu.org/licenses/fdl-1.3.html.en)

## 謝辞
本データセットを構築するにあたり、国立国語研究所 共同研究プロジェクト 異分野融合型共同研究「テキスト読み上げのための読みの曖昧性の分類と読み推定タスクのデータセットの構築」の助成を受けました。深く感謝いたします。
